{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Using Azure's OpenAI Service with Parallel Processing\n",
    "\n",
    "This notebook performs sentiment analysis on financial auditor report sentences using the GPT-3.5 Turbo model from Azure's OpenAI service. The goal is to categorize the sentiment of each sentence as positive, neutral, or negative. A subset of 1000 samples from the \"auditor_sentiment\" dataset, available on Hugging Face's datasets hub, is utilized for this analysis.\n",
    "\n",
    "To optimize the workflow and efficiently handle a large volume of data, a custom Python class, `ParallelAPIRequester`, is used. This class is designed to manage and submit multiple requests in parallel, significantly speeding up the processing time compared to sequential submissions.\n",
    "\n",
    "The notebook will guide through the steps of loading the dataset, preparing, and sending parallel requests to the API.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "from datasets import load_dataset, Dataset\n",
    "from src.Parallel_LLM_API_Requester import ParallelAPIRequesterConfig, ParallelAPIRequester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'label'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a random subset of 1000 samples from the training set\n",
    "dataset = load_dataset(\"FinanceInc/auditor_sentiment\", split='train')\n",
    "dataset = dataset.shuffle(seed=42).select(range(1000))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: In the second quarter of 2010 , the group 's net profit rose to EUR3 .1 m from EUR2 .5 m in April-June 2009 .\n",
      "label: 2\n"
     ]
    }
   ],
   "source": [
    "#label: a label corresponding to the class as a string: 'positive' - (2), 'neutral' - (1), or 'negative' - (0)\n",
    "print(f\"sentence: {dataset[350]['sentence']}\")\n",
    "print(f\"label: {dataset[350]['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg = \"\"\"Assistant predicts the sentiment of a given text.\n",
    "After users input the text and a JSON template, Assistant will provide the suggested response.\"\"\"\n",
    "\n",
    "user_msg = \"\"\"{text}\n",
    "\n",
    "Respond the sentiment in JSON according to the template:\n",
    "{{\n",
    "    \"sentiment\": \"X\"\n",
    "}}\n",
    "\n",
    "Replace the 'X' exclusively with either '2' for positive, '1' for neutral or '0' for negative.\n",
    "Ensure the response strictly follows the format provided above.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of prepared_requests: 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': \"We have also cut our price projections for paper and packaging , '' an analyst with Goldman Sachs said on a note on Monday .\",\n",
       "  'actual_label': 0,\n",
       "  'api_message': [{'role': 'system',\n",
       "    'content': 'Assistant predicts the sentiment of a given text.\\nAfter users input the text and a JSON template, Assistant will provide the suggested response.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'We have also cut our price projections for paper and packaging , \\'\\' an analyst with Goldman Sachs said on a note on Monday .\\n\\nRespond the sentiment in JSON according to the template:\\n{\\n    \"sentiment\": \"X\"\\n}\\n\\nReplace the \\'X\\' exclusively with either \\'2\\' for positive, \\'1\\' for neutral or \\'0\\' for negative.\\nEnsure the response strictly follows the format provided above.\\n'}]},\n",
       " {'text': 'No financial details were revealed .',\n",
       "  'actual_label': 1,\n",
       "  'api_message': [{'role': 'system',\n",
       "    'content': 'Assistant predicts the sentiment of a given text.\\nAfter users input the text and a JSON template, Assistant will provide the suggested response.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'No financial details were revealed .\\n\\nRespond the sentiment in JSON according to the template:\\n{\\n    \"sentiment\": \"X\"\\n}\\n\\nReplace the \\'X\\' exclusively with either \\'2\\' for positive, \\'1\\' for neutral or \\'0\\' for negative.\\nEnsure the response strictly follows the format provided above.\\n'}]}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the requests to be sent to the API\n",
    "#Note: Make sure in each request, you have 'api_message' dictionary with 'role' (either \"system\" or \"user\") and 'content' keys\n",
    "\n",
    "prepared_requests = []\n",
    "for example in dataset:\n",
    "    prepared_requests.append({\n",
    "                        \"text\": example['sentence'],\n",
    "                        \"actual_label\": example['label'],\n",
    "                        \"api_message\": [\n",
    "                            {\"role\": \"system\", \"content\": system_msg},\n",
    "                            {\"role\": \"user\", \"content\": user_msg.format(text=example['sentence'])}\n",
    "                        ]\n",
    "                    })\n",
    "\n",
    "print(f\"len of prepared_requests: {len(prepared_requests)}\")\n",
    "prepared_requests[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the parameters and initialize the paralle API requester class\n",
    "\n",
    "# Note:  Ensure the appropriate values in the config file are configured to avoid API request or token request rejections due to limit overreaches.\n",
    "with open(\"src/configs/sentiment_analysis.yml\", \"r\") as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "config = ParallelAPIRequesterConfig(**config_dict)\n",
    "\n",
    "llm_sentiment_gpt35 = ParallelAPIRequester(name = \"gpt35_llm\", config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost after 100/1000 requests: 0.009487000000000002 dollars\n",
      "Total cost after 200/1000 requests: 0.019251500000000005 dollars\n",
      "Total cost after 300/1000 requests: 0.027012999999999992 dollars\n",
      "Total cost after 400/1000 requests: 0.03617349999999998 dollars\n",
      "Error while processing: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Total cost after 500/1000 requests: 0.04313099999999999 dollars\n",
      "Retrying...\n",
      "Total cost after 600/1000 requests: 0.04801449999999994 dollars\n",
      "Total cost after 700/1000 requests: 0.054798499999999924 dollars\n",
      "Error while processing: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "All retry attempts failed for: <src.Parallel_LLM_API_Requester.ParallelAPIRequester object at 0x11069a310>\n",
      "Returning None for this request.\n",
      "Total cost after 800/1000 requests: 0.06406049999999994 dollars\n",
      "Total cost after 900/1000 requests: 0.07316349999999999 dollars\n",
      "Total cost after 1000/1000 requests: 0.07634450000000001 dollars\n",
      "Total time taken: 0 hours, 1 minutes, 24 seconds\n"
     ]
    }
   ],
   "source": [
    "# Submit all the requests to the class and get the responses\n",
    "results = llm_sentiment_gpt35.get_responses_parallel(prepared_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to a json file\n",
    "with open(\"generatad_data/sentiment_analysis.json\", 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results from the json file\n",
    "with open(\"generatad_data/sentiment_analysis.json\", 'r') as f:\n",
    "    results_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Compared with the FTSE 100 index , which rose 94.9 points ( or 1.6 % ) on the day , this was a relative price change of -0.4 % .',\n",
       " 'actual_label': 0,\n",
       " 'api__system_message': 'Assistant predicts the sentiment of a given text.\\nAfter users input the text and a JSON template, Assistant will provide the suggested response.',\n",
       " 'api__user_message': 'Compared with the FTSE 100 index , which rose 94.9 points ( or 1.6 % ) on the day , this was a relative price change of -0.4 % .\\n\\nRespond the sentiment in JSON according to the template:\\n{\\n    \"sentiment\": \"X\"\\n}\\n\\nReplace the \\'X\\' exclusively with either \\'2\\' for positive, \\'1\\' for neutral or \\'0\\' for negative.\\nEnsure the response strictly follows the format provided above.\\n',\n",
       " 'response': {'sentiment': '0'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_json[30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ParallelAPIRequester` class efficiently processes all 1000 requests in a very short time (1 minute and 24 seconds), adding a `response` key to each request in the input list, maintaining the relationship between each request and its corresponding response.\n",
    "\n",
    "The `ParallelAPIRequester` class effectively manages errors through robust mechanisms. It gracefully handles interruptions (example above caused by content policy violations) with automated retries and detailed logging, allowing the process to proceed smoothly despite errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
